{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pydub import AudioSegment\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Define the audio file path\n",
    "audio_file = \"audio/5760-Nano-L2.mp3\"\n",
    "\n",
    "# Check if Metal Performance Shaders (MPS) is available for GPU acceleration on macOS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use MPS device if available\n",
    "    print(\"Using Metal GPU acceleration\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU if MPS is not available\n",
    "    print(\"Metal not available, using CPU\")\n",
    "\n",
    "# Set up the automatic speech recognition pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\",  # Specify the Whisper model to use\n",
    "    torch_dtype=torch.float16,  # Use float16 for faster computation and reduced memory usage\n",
    "    device=device,  # Use the selected device (MPS or CPU)\n",
    "    return_timestamps=True,  # Return word-level timestamps in the output\n",
    ")\n",
    "\n",
    "# Generate a unique filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f'transcription_{timestamp}.txt'\n",
    "\n",
    "# Define a function to process audio in chunks and write to file\n",
    "def process_in_chunks(audio_file, chunk_length_s=30, output_file=output_filename):\n",
    "    # Load the audio file using pydub\n",
    "    audio = AudioSegment.from_mp3(audio_file)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    chunk_length_ms = chunk_length_s * 1000  # Convert chunk length to milliseconds\n",
    "    chunks = math.ceil(len(audio) / chunk_length_ms)  # Calculate the number of chunks needed\n",
    "\n",
    "    # Start measuring the transcription time\n",
    "    start_time = time.time()\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for i in range(chunks):\n",
    "            # Determine the start and end times for the current chunk\n",
    "            start_time_chunk = i * chunk_length_ms\n",
    "            end_time_chunk = (i + 1) * chunk_length_ms\n",
    "            chunk = audio[start_time_chunk:end_time_chunk]  # Extract the audio chunk\n",
    "\n",
    "            # Create a temporary file for the audio chunk\n",
    "            chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "            chunk.export(chunk_file, format=\"wav\")  # Export the chunk as a WAV file\n",
    "\n",
    "            # Perform transcription on the audio chunk\n",
    "            result = pipe(chunk_file, language=\"en\")  # Transcribe the chunk\n",
    "\n",
    "            # Write the chunk's transcription to file\n",
    "            f.write(result[\"text\"] + \" \")\n",
    "            f.flush()  # Ensure it's written immediately\n",
    "\n",
    "            # Clean up the temporary file\n",
    "            os.remove(chunk_file)\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Processed chunk {i+1}/{chunks}\")\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Transcription completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return output_file\n",
    "\n",
    "# Process the entire audio file in chunks and write to file\n",
    "try:\n",
    "    output_file = process_in_chunks(audio_file)\n",
    "    print(f\"Transcription saved to '{output_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during transcription: {e}\")\n",
    "\n",
    "# Print the device and model data type information\n",
    "print(f\"Device: {pipe.device}\")\n",
    "print(f\"Model dtype: {pipe.model.dtype}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
