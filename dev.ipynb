{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"audio/5760-Nano-L2.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal GPU acceleration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/opt/anaconda3/envs/transcribe311/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import time\n",
    "\n",
    "# Path to the audio file\n",
    "audio_file = \"audio/5760-Nano-L2.mp3\"\n",
    "\n",
    "# Check if Metal Performance Shaders (MPS) is available for GPU acceleration\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Metal GPU acceleration\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Metal not available, using CPU\")\n",
    "\n",
    "# Set up the automatic speech recognition pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", \n",
    "                model=\"openai/whisper-large-v3\",  # Using the large-v3 Whisper model\n",
    "                torch_dtype=torch.float16,  # Using half-precision for efficiency\n",
    "                device=device,  # Using the device determined above\n",
    "                return_timestamps=True)  # Enable timestamp generation\n",
    "\n",
    "# Start timing the transcription process\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform the transcription\n",
    "result = pipe(audio_file)\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# Print the results\n",
    "print(f\"Transcription completed in {elapsed_time:.2f} seconds\")\n",
    "print(\"Transcription result:\")\n",
    "print(result[\"text\"])\n",
    "\n",
    "# Print device and model information for debugging\n",
    "print(f\"Device: {pipe.device}\")\n",
    "print(f\"Model dtype: {pipe.model.dtype}\")\n",
    "\n",
    "# Function to process long audio files in chunks\n",
    "def process_in_chunks(audio_file, chunk_length_s=30):\n",
    "    from pydub import AudioSegment\n",
    "    import math\n",
    "    import os\n",
    "\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_mp3(audio_file)\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    chunk_length_ms = chunk_length_s * 1000\n",
    "    chunks = math.ceil(len(audio) / chunk_length_ms)\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    for i in range(chunks):\n",
    "        # Extract a chunk of audio\n",
    "        start_time = i * chunk_length_ms\n",
    "        end_time = (i + 1) * chunk_length_ms\n",
    "        chunk = audio[start_time:end_time]\n",
    "        \n",
    "        # Save the chunk as a temporary WAV file\n",
    "        chunk_file = f\"temp_chunk_{i}.wav\"\n",
    "        chunk.export(chunk_file, format=\"wav\")\n",
    "\n",
    "        # Transcribe the chunk\n",
    "        result = pipe(chunk_file, language=\"en\")\n",
    "        transcriptions.append(result[\"text\"])\n",
    "\n",
    "        # Clean up the temporary file\n",
    "        os.remove(chunk_file)\n",
    "\n",
    "    # Join all transcriptions into a single string\n",
    "    return \" \".join(transcriptions)\n",
    "\n",
    "# Process the entire audio file in chunks\n",
    "full_transcription = process_in_chunks(audio_file)\n",
    "print(\"Full transcription:\")\n",
    "print(full_transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcribe311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
